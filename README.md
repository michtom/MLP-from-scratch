# MLP from scratch
An implementation of MLP Neural Network using plain numpy, with backpropagation, momentum, RMSProp and different activtion functions. The architecture of a network, learning rate, number of epochs, used method (momentum, RMSProp or neither) with its parameters and the activity function can be adjusted.

Made during Computational Intelligence Methods in Data Analysis course at Faculty of Mathematics and Information Science, Warsaw University of Technology. The notebook is a solution for one of the tasks during the course.

Author: Micha≈Ç Tomczyk
